{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Beauty Retail Marketing Analysis\n",
    "\n",
    "## Project Overview\n",
    "This notebook analyzes **10,322 beauty products** from 1,090+ brands across 4 e-commerce platforms to understand customer behavior, pricing strategies, and market segmentation.\n",
    "\n",
    "**Key Questions:**\n",
    "- What drives customer satisfaction?\n",
    "- How do pricing strategies affect ratings?\n",
    "- Can we predict product ratings?\n",
    "- What market segments exist?\n",
    "\n",
    "**Dataset:** Multi-platform beauty product data (Amazon, Flipkart, Sephora, Ulta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/cleaned_dataset.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality summary\n",
    "print(\"=== DATA QUALITY REPORT ===\")\n",
    "print(f\"Total products: {len(df):,}\")\n",
    "print(f\"Unique brands: {df['Brand'].nunique():,}\")\n",
    "print(f\"Platforms: {', '.join(df['Website'].unique())}\")\n",
    "print(f\"Product categories: {df['Category'].nunique()}\")\n",
    "print(f\"Product forms: {df['Form'].nunique()}\")\n",
    "print(f\"\\nRating range: {df['Rating'].min():.1f} - {df['Rating'].max():.1f}\")\n",
    "print(f\"Price range: ${df['Price ($)'].min():.0f} - ${df['Price ($)'].max():,.0f}\")\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "### 2.1 Rating Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rating_dist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['Rating'], bins=25, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(df['Rating'].median(), color='red', linestyle='--', label=f'Median: {df[\"Rating\"].median():.2f}')\n",
    "axes[0].set_title('Rating Distribution', fontsize=14)\n",
    "axes[0].set_xlabel('Rating')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['Rating'], vert=False, patch_artist=True,\n",
    "                boxprops=dict(facecolor='skyblue'),\n",
    "                medianprops=dict(color='red', linewidth=2))\n",
    "axes[1].set_title('Rating Distribution (Box Plot)', fontsize=14)\n",
    "axes[1].set_xlabel('Rating')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/rating_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Rating Statistics:\")\n",
    "print(df['Rating'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2_2",
   "metadata": {},
   "source": [
    "### 2.2 Price vs Rating Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "price_rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price vs Rating by Product Form\n",
    "df_form = df.groupby('Form').agg({'Price ($)': 'mean', 'Rating': 'mean'}).reset_index()\n",
    "correlation = df_form['Price ($)'].corr(df_form['Rating'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_form['Price ($)'], df_form['Rating'], s=100, alpha=0.6, edgecolors='black')\n",
    "plt.title(f'Price vs Rating by Product Form (Correlation: {correlation:.3f})', fontsize=14)\n",
    "plt.xlabel('Average Price ($)', fontsize=12)\n",
    "plt.ylabel('Average Rating', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df_form['Price ($)'], df_form['Rating'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(df_form['Price ($)'], p(df_form['Price ($)']), \"r--\", alpha=0.8, label='Trend line')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/price_vs_rating.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nKey Finding: Price-Rating correlation = {correlation:.3f}\")\n",
    "print(\"Negative correlation suggests higher prices DON'T guarantee higher ratings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2_3",
   "metadata": {},
   "source": [
    "### 2.3 Platform Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "platform_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Website comparison\n",
    "df_website = df.groupby('Website').agg({\n",
    "    'Price ($)': 'mean',\n",
    "    'Rating': 'mean',\n",
    "    'Product name': 'count'\n",
    "}).rename(columns={'Product name': 'Count'}).reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart - Price\n",
    "axes[0].bar(df_website['Website'], df_website['Price ($)'], color='steelblue', edgecolor='black')\n",
    "axes[0].set_title('Average Price by Platform', fontsize=14)\n",
    "axes[0].set_ylabel('Average Price ($)', fontsize=12)\n",
    "axes[0].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Bar chart - Rating\n",
    "axes[1].bar(df_website['Website'], df_website['Rating'], color='coral', edgecolor='black')\n",
    "axes[1].set_title('Average Rating by Platform', fontsize=14)\n",
    "axes[1].set_ylabel('Average Rating', fontsize=12)\n",
    "axes[1].set_ylim(3.5, 4.5)\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/platform_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlatform Statistics:\")\n",
    "print(df_website)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Creating new features to improve model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature-engineered dataset\n",
    "df_features = pd.read_csv('../data/data_with_features.csv')\n",
    "\n",
    "print(\"Engineered Features:\")\n",
    "print(\"1. Price_Per_Rating: Price divided by rating (value metric)\")\n",
    "print(\"2. Is_Premium: Binary flag for products in top 25% price range\")\n",
    "print(\"3. Brand_Avg_Rating: Average rating for each brand\")\n",
    "print(\"4. Category_Avg_Price: Average price for each category\")\n",
    "print(\"\\nSample data:\")\n",
    "df_features[['Price ($)', 'Rating', 'Price_Per_Rating', 'Is_Premium', 'Brand_Avg_Rating']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "numeric_cols = ['Price ($)', 'Rating', 'Price_Per_Rating', 'Is_Premium', \n",
    "                'Brand_Avg_Rating', 'Category_Avg_Price']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df_features[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            fmt='.3f', square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Correlations with Rating:\")\n",
    "print(correlation_matrix['Rating'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "## 4. Predictive Modeling\n",
    "\n",
    "### 4.1 KNN Regression for Rating Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knn_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode categorical variables\n",
    "df_model = df_features.copy()\n",
    "df_model['Website_Encoded'] = le.fit_transform(df_model['Website'])\n",
    "df_model['Category_Encoded'] = le.fit_transform(df_model['Category'])\n",
    "df_model['Subcategory_Encoded'] = le.fit_transform(df_model['Subcategory'])\n",
    "df_model['Form_Encoded'] = le.fit_transform(df_model['Form'])\n",
    "\n",
    "# Select features\n",
    "feature_cols = ['Price ($)', 'Website_Encoded', 'Category_Encoded', \n",
    "                'Subcategory_Encoded', 'Form_Encoded', 'Price_Per_Rating',\n",
    "                'Is_Premium', 'Brand_Avg_Rating']\n",
    "\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['Rating']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knn_training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'n_neighbors': [5, 10, 15, 20, 25, 30],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "print(\"Training KNN model with GridSearchCV...\")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score (MSE): {-grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "best_knn = grid_search.best_estimator_\n",
    "test_score = best_knn.score(X_test_scaled, y_test)\n",
    "predictions = best_knn.predict(X_test_scaled)\n",
    "mse = np.mean((predictions - y_test) ** 2)\n",
    "\n",
    "print(f\"\\nTest R² score: {test_score:.4f}\")\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"Test RMSE: {np.sqrt(mse):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance using permutation importance\n",
    "perm_importance = permutation_importance(best_knn, X_test_scaled, y_test, \n",
    "                                         n_repeats=10, random_state=42)\n",
    "\n",
    "# Create importance dataframe\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': perm_importance.importances_mean\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='teal', edgecolor='black')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.title('Feature Importance (Permutation)', fontsize=14)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature Importance Rankings:\")\n",
    "print(importance_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5",
   "metadata": {},
   "source": [
    "## 5. Customer Segmentation with K-Means\n",
    "\n",
    "### 5.1 Finding Optimal Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elbow_method",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare clustering data\n",
    "cluster_features = df_features[['Price ($)', 'Rating']].dropna()\n",
    "scaler_cluster = StandardScaler()\n",
    "cluster_scaled = scaler_cluster.fit_transform(cluster_features)\n",
    "\n",
    "# Elbow method\n",
    "inertias = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(cluster_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (k)', fontsize=12)\n",
    "plt.ylabel('Inertia (Within-cluster sum of squares)', fontsize=12)\n",
    "plt.title('Elbow Method for Optimal k', fontsize=14)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.axvline(x=4, color='red', linestyle='--', label='Optimal k=4')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/optimal_k.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Inertia values for different k:\")\n",
    "for k, inertia in zip(K_range, inertias):\n",
    "    print(f\"k={k}: {inertia:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5_2",
   "metadata": {},
   "source": [
    "### 5.2 Apply K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kmeans_clustering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-Means with optimal k=4\n",
    "optimal_k = 4\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df_features['Cluster'] = kmeans.fit_predict(cluster_scaled)\n",
    "\n",
    "# Cluster profiles\n",
    "cluster_summary = df_features.groupby('Cluster').agg({\n",
    "    'Price ($)': ['mean', 'median', 'std'],\n",
    "    'Rating': ['mean', 'median', 'std'],\n",
    "    'Product name': 'count'\n",
    "}).round(2)\n",
    "\n",
    "cluster_summary.columns = ['_'.join(col) for col in cluster_summary.columns]\n",
    "cluster_summary = cluster_summary.rename(columns={'Product name_count': 'Count'})\n",
    "\n",
    "print(\"\\nCluster Profiles:\")\n",
    "print(cluster_summary)\n",
    "\n",
    "# Define cluster names\n",
    "cluster_names = {\n",
    "    0: 'Premium',\n",
    "    1: 'Best Value',\n",
    "    2: 'Standard',\n",
    "    3: 'Budget'\n",
    "}\n",
    "df_features['Cluster_Name'] = df_features['Cluster'].map(cluster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cluster_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(df_features['Price ($)'], df_features['Rating'], \n",
    "                     c=df_features['Cluster'], cmap='viridis', \n",
    "                     alpha=0.6, edgecolors='black', s=50)\n",
    "\n",
    "# Plot cluster centers\n",
    "centers = scaler_cluster.inverse_transform(kmeans.cluster_centers_)\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=300, alpha=0.8, \n",
    "           edgecolors='black', linewidth=2, marker='X', label='Centroids')\n",
    "\n",
    "plt.xlabel('Price ($)', fontsize=12)\n",
    "plt.ylabel('Rating', fontsize=12)\n",
    "plt.title('Customer Segmentation: Price vs Rating (K-Means, k=4)', fontsize=14)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/clusters_by_price_rating.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Distribution by cluster\n",
    "print(\"\\nCluster Distribution:\")\n",
    "print(df_features['Cluster_Name'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6",
   "metadata": {},
   "source": [
    "## 6. Key Findings & Business Insights\n",
    "\n",
    "### Summary of Results:\n",
    "\n",
    "#### 1. Price-Rating Paradox\n",
    "- **Correlation: -0.31** between price and rating for product forms\n",
    "- Higher prices do NOT guarantee higher customer satisfaction\n",
    "- Budget-friendly products (aerosols, foams) achieve excellent ratings\n",
    "\n",
    "#### 2. Brand Reputation is Key\n",
    "- **Brand Average Rating** is the strongest predictor (importance: 0.447)\n",
    "- Brand trust > Price, Platform, or Category\n",
    "- Consistent quality builds long-term customer satisfaction\n",
    "\n",
    "#### 3. Platform-Agnostic Quality\n",
    "- Customer ratings remain consistent across all platforms\n",
    "- Platform choice doesn't drive satisfaction\n",
    "- Product quality matters more than where it's sold\n",
    "\n",
    "#### 4. Market Segmentation\n",
    "**Four distinct customer segments identified:**\n",
    "\n",
    "| Cluster | Segment | Avg Price | Avg Rating | Strategy |\n",
    "|---------|---------|-----------|------------|----------|\n",
    "| 0 | Premium | $5,490 | 4.16 | High-end positioning |\n",
    "| 1 | Best Value | $1,493 | 4.31 | **Optimal target** |\n",
    "| 2 | Standard | $1,404 | 4.09 | Mass market |\n",
    "| 3 | Budget | $575 | 3.91 | Price-conscious |\n",
    "\n",
    "#### 5. Model Performance\n",
    "- **KNN Regressor Test MSE: 0.139** (rating prediction)\n",
    "- Successfully predicts ratings with 8 features\n",
    "- GridSearchCV optimal params: k=15, weights=distance, metric=euclidean\n",
    "\n",
    "### Business Recommendations:\n",
    "\n",
    "1. **Pricing Strategy:** Don't overprice - focus on value perception\n",
    "2. **Brand Building:** Invest in consistent product quality across portfolio\n",
    "3. **Product Development:** Target the \"Best Value\" segment (mid-tier pricing, high ratings)\n",
    "4. **Marketing:** Emphasize product quality over platform prestige\n",
    "5. **Customer Segmentation:** Tailor strategies for each of the 4 market segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final statistics summary\n",
    "print(\"=\"*60)\n",
    "print(\"BEAUTY RETAIL MARKETING ANALYSIS - FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset Size: {len(df_features):,} products\")\n",
    "print(f\"Brands Analyzed: {df_features['Brand'].nunique():,}\")\n",
    "print(f\"Platforms: {', '.join(df_features['Website'].unique())}\")\n",
    "print(f\"\\nPrice Range: ${df_features['Price ($)'].min():.0f} - ${df_features['Price ($)'].max():,.0f}\")\n",
    "print(f\"Rating Range: {df_features['Rating'].min():.1f} - {df_features['Rating'].max():.1f}\")\n",
    "print(f\"Median Rating: {df_features['Rating'].median():.2f}\")\n",
    "print(f\"\\nPrice-Rating Correlation: {df_features['Price ($)'].corr(df_features['Rating']):.3f}\")\n",
    "print(f\"\\nModel Performance (KNN):\")\n",
    "print(f\"  - Test MSE: {mse:.4f}\")\n",
    "print(f\"  - Test RMSE: {np.sqrt(mse):.4f}\")\n",
    "print(f\"  - R² Score: {test_score:.4f}\")\n",
    "print(f\"\\nCustomer Segments: {optimal_k}\")\n",
    "print(f\"\\nTop 3 Most Important Features:\")\n",
    "print(importance_df.head(3).to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
